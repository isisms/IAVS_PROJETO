{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07868495",
   "metadata": {},
   "source": [
    "# Etapa 5 ‚Äì Apoio √† Avalia√ß√£o da IA\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://img.icons8.com/ios-filled/100/artificial-intelligence.png\" width=\"80\" alt=\"√çcone IA\"/>\n",
    "</p>\n",
    "Subetapa: Filtragem dos Par√°grafos para Gera√ß√£o de Perguntas\n",
    "\n",
    "<img src=\"https://img.icons8.com/ios-filled/50/000000/right--v1.png\" width=\"24\" style=\"vertical-align:middle; margin-right:8px;\"/> Objetivo da Subetapa\n",
    "Durante a prepara√ß√£o do corpus para a gera√ß√£o autom√°tica de perguntas, observou-se que alguns arquivos .txt, mesmo ap√≥s as etapas anteriores de limpeza, ainda continham trechos irrelevantes. Esses trechos, quando enviados ao modelo de NLP, causavam lentid√£o no processamento e geravam perguntas mal formuladas, com baixa utilidade para fins de valida√ß√£o.\n",
    "\n",
    "Para resolver esse gargalo, foi desenvolvido um script de filtragem sem√¢ntica automatizada. Ele identifica e remove par√°grafos com conte√∫do n√£o t√©cnico ou administrativo, como nomes de autores, contatos institucionais, fichas catalogr√°ficas, endere√ßos e notas editoriais.\n",
    "\n",
    "**O que o Script Faz**\n",
    "O script executa as seguintes tarefas:\n",
    "\n",
    "- L√™ o arquivo `paragrafos_validos_corpus.xlsx`, que cont√©m todos os par√°grafos extra√≠dos dos arquivos .txt considerados v√°lidos estruturalmente.\n",
    "- Aplica uma fun√ß√£o de filtragem sem√¢ntica (`paragrafo_relevante`):\n",
    "    - Remove par√°grafos curtos (com menos de 6 palavras).\n",
    "    - Exclui par√°grafos que contenham padr√µes de texto como:\n",
    "        - Nomes de autores e respons√°veis t√©cnicos;\n",
    "        - Endere√ßos e e-mails;\n",
    "        - Informa√ß√µes de publica√ß√£o (tiragem, edi√ß√£o, vers√£o);\n",
    "        - Trechos gen√©ricos como ‚Äúanexo‚Äù, ‚Äú√≠ndice‚Äù, ‚Äúap√™ndice‚Äù;\n",
    "        - Informa√ß√µes institucionais repetitivas (ex: ‚ÄúMinist√©rio da Sa√∫de‚Äù).\n",
    "\n",
    "**Cria dois novos arquivos:** <img src=\"https://img.icons8.com/ios-filled/50/000000/document--v1.png\" width=\"24\" style=\"vertical-align:middle; margin-left:8px;\"/>\n",
    "\n",
    "*paragrafos_filtrados_corpus.xlsx: apenas com os par√°grafos considerados relevantes.\n",
    "\n",
    "relatorio_filtragem_paragrafos.xlsx: com estat√≠sticas da filtragem (totais e percentuais) e amostras dos par√°grafos exclu√≠dos e mantidos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694747f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd292b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Lendo arquivo...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string argument expected, got 'ExpatError'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExpatError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1706\u001b[39m, in \u001b[36mXMLParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1706\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser.Parse(data, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "\u001b[31mExpatError\u001b[39m: not well-formed (invalid token): line 1, column 7209623",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mParseError\u001b[39m                                Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Lendo arquivo...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m df = pd.read_excel(ARQUIVO_ENTRADA)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚öôÔ∏è Aplicando filtro sem√¢ntico...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = io.parse(\n\u001b[32m    509\u001b[39m         sheet_name=sheet_name,\n\u001b[32m    510\u001b[39m         header=header,\n\u001b[32m    511\u001b[39m         names=names,\n\u001b[32m    512\u001b[39m         index_col=index_col,\n\u001b[32m    513\u001b[39m         usecols=usecols,\n\u001b[32m    514\u001b[39m         dtype=dtype,\n\u001b[32m    515\u001b[39m         converters=converters,\n\u001b[32m    516\u001b[39m         true_values=true_values,\n\u001b[32m    517\u001b[39m         false_values=false_values,\n\u001b[32m    518\u001b[39m         skiprows=skiprows,\n\u001b[32m    519\u001b[39m         nrows=nrows,\n\u001b[32m    520\u001b[39m         na_values=na_values,\n\u001b[32m    521\u001b[39m         keep_default_na=keep_default_na,\n\u001b[32m    522\u001b[39m         na_filter=na_filter,\n\u001b[32m    523\u001b[39m         verbose=verbose,\n\u001b[32m    524\u001b[39m         parse_dates=parse_dates,\n\u001b[32m    525\u001b[39m         date_parser=date_parser,\n\u001b[32m    526\u001b[39m         date_format=date_format,\n\u001b[32m    527\u001b[39m         thousands=thousands,\n\u001b[32m    528\u001b[39m         decimal=decimal,\n\u001b[32m    529\u001b[39m         comment=comment,\n\u001b[32m    530\u001b[39m         skipfooter=skipfooter,\n\u001b[32m    531\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    532\u001b[39m     )\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03mParse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m>>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reader.parse(\n\u001b[32m   1617\u001b[39m     sheet_name=sheet_name,\n\u001b[32m   1618\u001b[39m     header=header,\n\u001b[32m   1619\u001b[39m     names=names,\n\u001b[32m   1620\u001b[39m     index_col=index_col,\n\u001b[32m   1621\u001b[39m     usecols=usecols,\n\u001b[32m   1622\u001b[39m     converters=converters,\n\u001b[32m   1623\u001b[39m     true_values=true_values,\n\u001b[32m   1624\u001b[39m     false_values=false_values,\n\u001b[32m   1625\u001b[39m     skiprows=skiprows,\n\u001b[32m   1626\u001b[39m     nrows=nrows,\n\u001b[32m   1627\u001b[39m     na_values=na_values,\n\u001b[32m   1628\u001b[39m     parse_dates=parse_dates,\n\u001b[32m   1629\u001b[39m     date_parser=date_parser,\n\u001b[32m   1630\u001b[39m     date_format=date_format,\n\u001b[32m   1631\u001b[39m     thousands=thousands,\n\u001b[32m   1632\u001b[39m     comment=comment,\n\u001b[32m   1633\u001b[39m     skipfooter=skipfooter,\n\u001b[32m   1634\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1635\u001b[39m     **kwds,\n\u001b[32m   1636\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    777\u001b[39m file_rows_needed = \u001b[38;5;28mself\u001b[39m._calc_rows(header, index_col, skiprows, nrows)\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m data = \u001b[38;5;28mself\u001b[39m.get_sheet_data(sheet, file_rows_needed)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    780\u001b[39m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_data\u001b[39m\u001b[34m(self, sheet, file_rows_needed)\u001b[39m\n\u001b[32m    614\u001b[39m last_row_with_data = -\u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet.rows):\n\u001b[32m    616\u001b[39m     converted_row = [\u001b[38;5;28mself\u001b[39m._convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[39m, in \u001b[36mReadOnlyWorksheet._cells_by_row\u001b[39m\u001b[34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[39m\n\u001b[32m     78\u001b[39m parser = WorkSheetParser(src,\n\u001b[32m     79\u001b[39m                          \u001b[38;5;28mself\u001b[39m._shared_strings,\n\u001b[32m     80\u001b[39m                          data_only=\u001b[38;5;28mself\u001b[39m.parent.data_only,\n\u001b[32m     81\u001b[39m                          epoch=\u001b[38;5;28mself\u001b[39m.parent.epoch,\n\u001b[32m     82\u001b[39m                          date_formats=\u001b[38;5;28mself\u001b[39m.parent._date_formats,\n\u001b[32m     83\u001b[39m                          timedelta_formats=\u001b[38;5;28mself\u001b[39m.parent._timedelta_formats)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser.parse():\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx > max_row:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[39m, in \u001b[36mWorkSheetParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m it = iterparse(\u001b[38;5;28mself\u001b[39m.source) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, element \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[32m    157\u001b[39m     tag_name = element.tag\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1236\u001b[39m, in \u001b[36miterparse.<locals>.iterator\u001b[39m\u001b[34m(source)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1236\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m pullparser.read_events()\n\u001b[32m   1237\u001b[39m     \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1312\u001b[39m, in \u001b[36mXMLPullParser.read_events\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m event\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1284\u001b[39m, in \u001b[36mXMLPullParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     \u001b[38;5;28mself\u001b[39m._parser.feed(data)\n\u001b[32m   1285\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1708\u001b[39m, in \u001b[36mXMLParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[32m-> \u001b[39m\u001b[32m1708\u001b[39m     \u001b[38;5;28mself\u001b[39m._raiseerror(v)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1615\u001b[39m, in \u001b[36mXMLParser._raiseerror\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   1614\u001b[39m err.position = value.lineno, value.offset\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[31mParseError\u001b[39m: not well-formed (invalid token): line 1, column 7209623 (<string>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2146\u001b[39m, in \u001b[36mInteractiveShell.showtraceback\u001b[39m\u001b[34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[39m\n\u001b[32m   2141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(etype, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n\u001b[32m   2144\u001b[39m     \u001b[38;5;66;03m# Though this won't be called by syntax errors in the input\u001b[39;00m\n\u001b[32m   2145\u001b[39m     \u001b[38;5;66;03m# line, there may be SyntaxError cases with imported code.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2146\u001b[39m     \u001b[38;5;28mself\u001b[39m.showsyntaxerror(filename, running_compiled_code)\n\u001b[32m   2147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m UsageError:\n\u001b[32m   2148\u001b[39m     \u001b[38;5;28mself\u001b[39m.show_usage_error(value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2236\u001b[39m, in \u001b[36mInteractiveShell.showsyntaxerror\u001b[39m\u001b[34m(self, filename, running_compiled_code)\u001b[39m\n\u001b[32m   2234\u001b[39m \u001b[38;5;66;03m# If the error occurred when executing compiled code, we should provide full stacktrace.\u001b[39;00m\n\u001b[32m   2235\u001b[39m elist = traceback.extract_tb(last_traceback) \u001b[38;5;28;01mif\u001b[39;00m running_compiled_code \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m stb = \u001b[38;5;28mself\u001b[39m.SyntaxTB.structured_traceback(etype, value, elist)\n\u001b[32m   2237\u001b[39m \u001b[38;5;28mself\u001b[39m._showtraceback(etype, value, stb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:1240\u001b[39m, in \u001b[36mSyntaxTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1238\u001b[39m         value.text = newtext\n\u001b[32m   1239\u001b[39m \u001b[38;5;28mself\u001b[39m.last_syntax_error = value\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SyntaxTB, \u001b[38;5;28mself\u001b[39m).structured_traceback(\n\u001b[32m   1241\u001b[39m     etype, value, etb, tb_offset=tb_offset, context=context\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:212\u001b[39m, in \u001b[36mListTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    210\u001b[39m     out_list.extend(\u001b[38;5;28mself\u001b[39m._format_list(elist))\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# The exception info should be a single entry in the list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m lines = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._format_exception_only(etype, evalue))\n\u001b[32m    213\u001b[39m out_list.append(lines)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Find chained exceptions if we have a traceback (not for exception-only mode)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:374\u001b[39m, in \u001b[36mListTB._format_exception_only\u001b[39m\u001b[34m(self, etype, value)\u001b[39m\n\u001b[32m    371\u001b[39m     s = \u001b[38;5;28mself\u001b[39m._some_str(value)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s:\n\u001b[32m    373\u001b[39m     output_list.append(\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    375\u001b[39m             stype_tokens\n\u001b[32m    376\u001b[39m             + [\n\u001b[32m    377\u001b[39m                 (Token.ExcName, \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    378\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    379\u001b[39m                 (Token, s),\n\u001b[32m    380\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m    381\u001b[39m             ]\n\u001b[32m    382\u001b[39m         )\n\u001b[32m    383\u001b[39m     )\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     output_list.append(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % stype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\utils\\PyColorize.py:66\u001b[39m, in \u001b[36mTheme.format\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: TokenStream) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pygments.format(stream, \u001b[38;5;28mself\u001b[39m._formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     formatter.format(tokens, realoutfile)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Formatter.format(\u001b[38;5;28mself\u001b[39m, tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_unencoded(tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:286\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# outfile.write( '!' + str(ottype) + '->' + str(ttype) + '!' )\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_found:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         outfile.write(value)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    289\u001b[39m     outfile.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string argument expected, got 'ExpatError'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string argument expected, got 'ExpatError'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3381\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3377\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3379\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3381\u001b[39m         \u001b[38;5;28mself\u001b[39m._format_exception_for_storage(result.error_in_exec)\n\u001b[32m   3382\u001b[39m     )\n\u001b[32m   3384\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3385\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3410\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3408\u001b[39m     \u001b[38;5;66;03m# Extract traceback if the error happened during compiled code execution\u001b[39;00m\n\u001b[32m   3409\u001b[39m     elist = traceback.extract_tb(tb) \u001b[38;5;28;01mif\u001b[39;00m running_compiled_code \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     stb = \u001b[38;5;28mself\u001b[39m.SyntaxTB.structured_traceback(etype, evalue, elist)\n\u001b[32m   3412\u001b[39m \u001b[38;5;66;03m# Handle UsageError with a simple message\u001b[39;00m\n\u001b[32m   3413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m UsageError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:1240\u001b[39m, in \u001b[36mSyntaxTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1238\u001b[39m         value.text = newtext\n\u001b[32m   1239\u001b[39m \u001b[38;5;28mself\u001b[39m.last_syntax_error = value\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SyntaxTB, \u001b[38;5;28mself\u001b[39m).structured_traceback(\n\u001b[32m   1241\u001b[39m     etype, value, etb, tb_offset=tb_offset, context=context\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:212\u001b[39m, in \u001b[36mListTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    210\u001b[39m     out_list.extend(\u001b[38;5;28mself\u001b[39m._format_list(elist))\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# The exception info should be a single entry in the list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m lines = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._format_exception_only(etype, evalue))\n\u001b[32m    213\u001b[39m out_list.append(lines)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Find chained exceptions if we have a traceback (not for exception-only mode)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:374\u001b[39m, in \u001b[36mListTB._format_exception_only\u001b[39m\u001b[34m(self, etype, value)\u001b[39m\n\u001b[32m    371\u001b[39m     s = \u001b[38;5;28mself\u001b[39m._some_str(value)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s:\n\u001b[32m    373\u001b[39m     output_list.append(\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    375\u001b[39m             stype_tokens\n\u001b[32m    376\u001b[39m             + [\n\u001b[32m    377\u001b[39m                 (Token.ExcName, \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    378\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    379\u001b[39m                 (Token, s),\n\u001b[32m    380\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m    381\u001b[39m             ]\n\u001b[32m    382\u001b[39m         )\n\u001b[32m    383\u001b[39m     )\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     output_list.append(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % stype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\utils\\PyColorize.py:66\u001b[39m, in \u001b[36mTheme.format\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: TokenStream) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pygments.format(stream, \u001b[38;5;28mself\u001b[39m._formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     formatter.format(tokens, realoutfile)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Formatter.format(\u001b[38;5;28mself\u001b[39m, tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_unencoded(tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:286\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# outfile.write( '!' + str(ottype) + '->' + str(ttype) + '!' )\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_found:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         outfile.write(value)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    289\u001b[39m     outfile.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string argument expected, got 'ExpatError'"
     ]
    }
   ],
   "source": [
    "# === CONFIGURA√á√ïES DE CAMINHO ===\n",
    "PASTA = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_ENTRADA = os.path.join(PASTA, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA, \"paragrafos_filtrados_corpus.xlsx\")\n",
    "ARQUIVO_RELATORIO = os.path.join(PASTA, \"relatorio_filtragem_paragrafos.xlsx\")\n",
    "\n",
    "# === FUN√á√ÉO DE FILTRAGEM ===\n",
    "def paragrafo_relevante(texto):\n",
    "    texto_limpo = texto.lower().strip()\n",
    "    padroes_excluir = [\n",
    "        r'nomes?[:\\-]',\n",
    "        r'e-mail|site:|www\\.',\n",
    "        r'cep:|quadra|srtv|endere',\n",
    "        r'coordena√ß√£o-geral|departamento',\n",
    "        r'minist√©rio da sa√∫de',\n",
    "        r'esta obra.*licen√ßa',\n",
    "        r'(nome|cargo) do autor',\n",
    "        r'sa√∫de p√∫blica brasileira.*acesso',\n",
    "        r'\\b(anexo|ap√™ndice|√≠ndice)\\b',\n",
    "        r'(autores?|vers√£o|tiragem|edi√ß√£o).*202[0-9]',\n",
    "        r'(sigla|significado) de ',\n",
    "        r'(organizador|respons√°vel|revis√£o)',\n",
    "    ]\n",
    "    for padrao in padroes_excluir:\n",
    "        if re.search(padrao, texto_limpo):\n",
    "            return False\n",
    "    if len(texto_limpo.split()) < 6:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# === EXECU√á√ÉO ===\n",
    "print(\"üîç Lendo arquivo...\")\n",
    "df = pd.read_excel(ARQUIVO_ENTRADA)\n",
    "\n",
    "print(\"‚öôÔ∏è Aplicando filtro sem√¢ntico...\")\n",
    "df[\"Relevante\"] = df[\"Texto\"].astype(str).apply(paragrafo_relevante)\n",
    "\n",
    "df_filtrado = df[df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "df_excluido = df[~df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "\n",
    "print(f\"‚úÖ Par√°grafos mantidos: {len(df_filtrado)}\")\n",
    "print(f\"üö´ Par√°grafos exclu√≠dos: {len(df_excluido)}\")\n",
    "\n",
    "# === SALVAR RESULTADO FILTRADO ===\n",
    "print(\"üíæ Salvando arquivo com par√°grafos filtrados...\")\n",
    "df_filtrado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "# === GERAR RELAT√ìRIO EM EXCEL COM AMOSTRAS ===\n",
    "print(\"üìù Gerando relat√≥rio...\")\n",
    "resumo = {\n",
    "    \"Total original\": [len(df)],\n",
    "    \"Total mantido\": [len(df_filtrado)],\n",
    "    \"Total exclu√≠do\": [len(df_excluido)],\n",
    "    \"% mantido\": [round(100 * len(df_filtrado) / len(df), 2)],\n",
    "    \"% exclu√≠do\": [round(100 * len(df_excluido) / len(df), 2)],\n",
    "}\n",
    "df_resumo = pd.DataFrame(resumo)\n",
    "\n",
    "amostra_mantido = df_filtrado.sample(min(5, len(df_filtrado)), random_state=1)\n",
    "amostra_excluido = df_excluido.sample(min(5, len(df_excluido)), random_state=1)\n",
    "\n",
    "with pd.ExcelWriter(ARQUIVO_RELATORIO) as writer:\n",
    "    df_resumo.to_excel(writer, sheet_name=\"Resumo\", index=False)\n",
    "    amostra_mantido.to_excel(writer, sheet_name=\"Amostra Mantido\", index=False)\n",
    "    amostra_excluido.to_excel(writer, sheet_name=\"Amostra Exclu√≠do\", index=False)\n",
    "\n",
    "print(\"üìä Relat√≥rio salvo com sucesso!\")\n",
    "print(f\"üìÅ Arquivo filtrado: {ARQUIVO_SAIDA}\")\n",
    "print(f\"üìÑ Relat√≥rio: {ARQUIVO_RELATORIO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef747724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosticar_pasta Antes da Etapa 2 ‚Äì Extra√ß√£o e limpeza de texto Diagn√≥stico visual de duplicados e nomes corrompidos\n",
    "#COME√áA AQUI\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "\n",
    "# === FUN√á√ïES AUXILIARES ===\n",
    "\n",
    "def calcular_hash(caminho_arquivo, limite=1024*1024):\n",
    "    \"\"\"Calcula hash de uma parte do arquivo (1 MB por padr√£o) para diagn√≥stico r√°pido.\"\"\"\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(caminho_arquivo, 'rb') as f:\n",
    "        sha256.update(f.read(limite))\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "def normalizar_nome(nome):\n",
    "    \"\"\"Remove repeti√ß√µes consecutivas de sufixos.\"\"\"\n",
    "    padrao = r'(txt_\\w+\\d{4})+'\n",
    "    return re.sub(padrao, lambda m: m.group(1), nome)\n",
    "\n",
    "def diagnosticar_pasta(pasta_raiz, saida_texto):\n",
    "    pasta_raiz = Path(pasta_raiz)\n",
    "    hash_map = {}\n",
    "    log_linhas = []\n",
    "    log_path = pasta_raiz / \"log_diagnostico.csv\"\n",
    "\n",
    "    saida_texto.insert(tk.END, f\"üîç Diagn√≥stico em: {pasta_raiz}\\n\")\n",
    "    saida_texto.insert(tk.END, \"Apenas leitura ‚Äî nenhum arquivo ser√° alterado.\\n\\n\")\n",
    "    saida_texto.update()\n",
    "\n",
    "    for caminho_arquivo in pasta_raiz.rglob(\"*.txt\"):\n",
    "        hash_arquivo = calcular_hash(caminho_arquivo)\n",
    "        nome_original = caminho_arquivo.name\n",
    "        caminho_pasta = caminho_arquivo.parent\n",
    "\n",
    "        # Verifica duplicidade de conte√∫do\n",
    "        if hash_arquivo in hash_map:\n",
    "            saida_texto.insert(tk.END, f\"‚ö†Ô∏è Poss√≠vel duplicado: {nome_original} (igual a {hash_map[hash_arquivo].name})\\n\")\n",
    "            log_linhas.append([\"DUPLICADO\", str(caminho_arquivo), \"Mesma hash de\", str(hash_map[hash_arquivo])])\n",
    "        else:\n",
    "            hash_map[hash_arquivo] = caminho_arquivo\n",
    "\n",
    "        # Verifica nome corrompido\n",
    "        nome_corrigido = normalizar_nome(nome_original)\n",
    "        if nome_corrigido != nome_original:\n",
    "            saida_texto.insert(tk.END, f\"üîÅ Nome suspeito: {nome_original} ‚Üí Sugerido: {nome_corrigido}\\n\")\n",
    "            log_linhas.append([\"NOME_CORROMPIDO\", str(caminho_arquivo), \"Sugerido\", nome_corrigido])\n",
    "\n",
    "    with open(log_path, mode='w', newline='', encoding='utf-8') as log_csv:\n",
    "        writer = csv.writer(log_csv)\n",
    "        writer.writerow([\"Tipo\", \"Arquivo\", \"Info\", \"Refer√™ncia/Sugest√£o\"])\n",
    "        writer.writerows(log_linhas)\n",
    "\n",
    "    saida_texto.insert(tk.END, f\"\\nüìÑ Log salvo em: {log_path}\\n\")\n",
    "    saida_texto.insert(tk.END, \"‚úÖ Diagn√≥stico conclu√≠do.\\n\")\n",
    "    saida_texto.update()\n",
    "\n",
    "# === INTERFACE GR√ÅFICA ===\n",
    "\n",
    "def iniciar_interface():\n",
    "    def escolher_pasta():\n",
    "        pasta = filedialog.askdirectory(title=\"Selecione a pasta 'corpus_final'\")\n",
    "        if pasta:\n",
    "            entrada_pasta.delete(0, tk.END)\n",
    "            entrada_pasta.insert(0, pasta)\n",
    "\n",
    "    def executar_diagnostico():\n",
    "        pasta_escolhida = entrada_pasta.get()\n",
    "        if not os.path.isdir(pasta_escolhida):\n",
    "            messagebox.showerror(\"Erro\", \"Selecione uma pasta v√°lida.\")\n",
    "            return\n",
    "        saida_texto.delete(1.0, tk.END)\n",
    "        diagnosticar_pasta(pasta_escolhida, saida_texto)\n",
    "\n",
    "    janela = tk.Tk()\n",
    "    janela.title(\"üîé Diagn√≥stico de Arquivos Duplicados e Nomes Corrompidos\")\n",
    "\n",
    "    tk.Label(janela, text=\"üìÅ Pasta Base:\").pack(pady=5)\n",
    "    entrada_pasta = tk.Entry(janela, width=60)\n",
    "    entrada_pasta.pack()\n",
    "    tk.Button(janela, text=\"Selecionar Pasta\", command=escolher_pasta).pack(pady=5)\n",
    "\n",
    "    tk.Button(janela, text=\"üîç Executar Diagn√≥stico\", command=executar_diagnostico, bg=\"blue\", fg=\"white\").pack(pady=10)\n",
    "\n",
    "    saida_texto = scrolledtext.ScrolledText(janela, width=100, height=25)\n",
    "    saida_texto.pack(padx=10, pady=10)\n",
    "\n",
    "    janela.mainloop()\n",
    "\n",
    "# Rodar\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc55887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Execu√ß√£o conclu√≠da. Log salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\log_execucao.csv\n"
     ]
    }
   ],
   "source": [
    "#executar_log_diagnostico remove duplicatas reais e renomeia arquivos com nome corrompido.Logo ap√≥s o diagn√≥stico, ainda na Etapa 2\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURA√á√ÉO ===\n",
    "PASTA_BASE = Path(r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\")  # ajuste se necess√°rio\n",
    "CAMINHO_LOG_DIAGNOSTICO = PASTA_BASE / \"log_diagnostico.csv\"\n",
    "CAMINHO_LOG_EXECUCAO = PASTA_BASE / \"log_execucao.csv\"\n",
    "\n",
    "# === LEITURA DO LOG ===\n",
    "with open(CAMINHO_LOG_DIAGNOSTICO, encoding='utf-8') as f:\n",
    "    leitor = csv.DictReader(f)\n",
    "    acoes = list(leitor)\n",
    "\n",
    "# === EXECU√á√ÉO DAS A√á√ïES ===\n",
    "log_execucao = []\n",
    "\n",
    "for linha in acoes:\n",
    "    tipo = linha['Tipo']\n",
    "    caminho_str = linha['Arquivo']\n",
    "    caminho_arquivo = Path(caminho_str)\n",
    "\n",
    "    if not caminho_arquivo.exists():\n",
    "        log_execucao.append([\"IGNORADO\", caminho_str, \"Arquivo n√£o encontrado\"])\n",
    "        continue\n",
    "\n",
    "    if tipo == \"DUPLICADO\":\n",
    "        try:\n",
    "            caminho_arquivo.unlink()\n",
    "            log_execucao.append([\"REMOVIDO\", caminho_str, \"Duplicata removida\"])\n",
    "            print(f\"üóëÔ∏è Removido: {caminho_str}\")\n",
    "        except Exception as e:\n",
    "            log_execucao.append([\"ERRO\", caminho_str, f\"Erro ao remover: {e}\"])\n",
    "\n",
    "    elif tipo == \"NOME_CORROMPIDO\":\n",
    "        sugestao = linha['Refer√™ncia/Sugest√£o']\n",
    "        novo_caminho = caminho_arquivo.parent / sugestao\n",
    "        contador = 1\n",
    "        while novo_caminho.exists():\n",
    "            novo_caminho = caminho_arquivo.parent / f\"{sugestao}_{contador}.txt\"\n",
    "            contador += 1\n",
    "        try:\n",
    "            caminho_arquivo.rename(novo_caminho)\n",
    "            log_execucao.append([\"RENOMEADO\", caminho_str, f\"Novo nome: {novo_caminho.name}\"])\n",
    "            print(f\"‚úèÔ∏è Renomeado: {caminho_arquivo.name} ‚Üí {novo_caminho.name}\")\n",
    "        except Exception as e:\n",
    "            log_execucao.append([\"ERRO\", caminho_str, f\"Erro ao renomear: {e}\"])\n",
    "\n",
    "# === SALVA LOG FINAL ===\n",
    "with open(CAMINHO_LOG_EXECUCAO, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"A√ß√£o\", \"Arquivo\", \"Detalhes\"])\n",
    "    writer.writerows(log_execucao)\n",
    "\n",
    "print(f\"\\n‚úÖ Execu√ß√£o conclu√≠da. Log salvo em: {CAMINHO_LOG_EXECUCAO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0cadef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Par√°grafos v√°lidos salvos em C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\paragrafos_validos_corpus.xlsx\n",
      "‚úÖ 20106 par√°grafos v√°lidos salvos em C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\paragrafos_validos_corpus.xlsx\n",
      "ü©∫ Diagn√≥stico salvo em C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\diagnostico_paragrafos_por_arquivo.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from openpyxl.cell.cell import ILLEGAL_CHARACTERS_RE\n",
    "\n",
    "# === CONFIGURA√á√ÉO ===\n",
    "PASTA_CORPUS = Path(r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\")\n",
    "ARQUIVO_SAIDA = PASTA_CORPUS / \"paragrafos_validos_corpus.xlsx\"\n",
    "ARQUIVO_DIAGNOSTICO = PASTA_CORPUS / \"diagnostico_paragrafos_por_arquivo.xlsx\"\n",
    "\n",
    "# === FUN√á√ïES ===\n",
    "def paragrafo_valido(paragrafo):\n",
    "    paragrafo = paragrafo.strip()\n",
    "    if len(paragrafo.split()) < 5:\n",
    "        return False\n",
    "    if re.match(r'^(\\d+|[‚Ä¢*])$', paragrafo):  # apenas n√∫mero ou bullet\n",
    "        return False\n",
    "    if sum(1 for palavra in [\"minist√©rio\", \"licen√ßa\", \"tiragem\", \"elabora√ß√£o\", \"cep\", \"autores\", \"vers√£o\", \"editora√ß√£o\"] if palavra in paragrafo.lower()) >= 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def limpar_caracteres_invalidos(texto):\n",
    "    return ILLEGAL_CHARACTERS_RE.sub(\"\", texto)\n",
    "\n",
    "def quebrar_paragrafos_brutos(texto):\n",
    "    # Substitui quebras de linha simples por espa√ßo (evita quebra errada)\n",
    "    texto = texto.replace(\"\\n\", \" \")\n",
    "    # Insere quebra for√ßada ap√≥s ponto final seguido de espa√ßo e letra mai√∫scula\n",
    "    texto = re.sub(r'\\. (?=[A-Z√Å√â√ç√ì√ö√á])', '.\\n\\n', texto)\n",
    "    # Divide onde houver \\n\\n for√ßado\n",
    "    return [p.strip() for p in texto.split('\\n\\n') if p.strip()]\n",
    "\n",
    "# === PROCESSAMENTO ===\n",
    "dados = []\n",
    "diagnostico = []\n",
    "\n",
    "for caminho_txt in PASTA_CORPUS.rglob(\"*.txt\"):\n",
    "    try:\n",
    "        with open(caminho_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "            conteudo = f.read()\n",
    "\n",
    "        # Divide usando segmenta√ß√£o for√ßada\n",
    "        paragrafos_raw = quebrar_paragrafos_brutos(conteudo)\n",
    "        paragrafos_validos = [p for p in paragrafos_raw if paragrafo_valido(p)]\n",
    "\n",
    "        for i, paragrafo in enumerate(paragrafos_validos, 1):\n",
    "            dados.append({\n",
    "                \"Arquivo\": caminho_txt.name,\n",
    "                \"Par√°grafo\": limpar_caracteres_invalidos(paragrafo),\n",
    "                \"N√∫mero do par√°grafo\": i\n",
    "            })\n",
    "\n",
    "        diagnostico.append({\n",
    "            \"Arquivo\": caminho_txt.name,\n",
    "            \"Total lidos\": len(paragrafos_raw),\n",
    "            \"V√°lidos mantidos\": len(paragrafos_validos),\n",
    "            \"Descartados\": len(paragrafos_raw) - len(paragrafos_validos)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao processar {caminho_txt.name}: {e}\")\n",
    "\n",
    "# === EXPORTA√á√ÉO ===\n",
    "df_paragrafos = pd.DataFrame(dados)\n",
    "df_paragrafos.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "df_diag = pd.DataFrame(diagnostico)\n",
    "df_diag.to_excel(ARQUIVO_DIAGNOSTICO, index=False)\n",
    "\n",
    "ARQUIVO_CSV = PASTA_CORPUS / \"paragrafos_validos_corpus.csv\"\n",
    "df_paragrafos.to_csv(ARQUIVO_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"üìÑ Par√°grafos v√°lidos salvos em {ARQUIVO_SAIDA}\")\n",
    "print(f\"‚úÖ {len(df_paragrafos)} par√°grafos v√°lidos salvos em {ARQUIVO_SAIDA}\")\n",
    "print(f\"ü©∫ Diagn√≥stico salvo em {ARQUIVO_DIAGNOSTICO}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee3879a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 39\n",
      "‚úÖ Arquivo √∫nico salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\resumo_arquivos_unicos.xlsx\n",
      "üìä Resumo por subpasta salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\resumo_por_subpasta.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURA√á√ÉO ===\n",
    "PASTA_BASE = Path(r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\")\n",
    "ARQUIVO_ENTRADA = PASTA_BASE / \"resumo_corpus_final.csv\"\n",
    "ARQUIVO_UNICOS = PASTA_BASE / \"resumo_arquivos_unicos.xlsx\"\n",
    "ARQUIVO_AGREGADO = PASTA_BASE / \"resumo_por_subpasta.xlsx\"\n",
    "\n",
    "# === LEITURA DO ARQUIVO DE RESUMO ===\n",
    "df = pd.read_csv(ARQUIVO_ENTRADA)\n",
    "\n",
    "# === REMOVER DUPLICATAS POR NOME BASE DO ARQUIVO ===\n",
    "# Extrai o nome base (sem partes repetidas)\n",
    "df[\"Arquivo_base\"] = df[\"Arquivo\"].str.extract(r\"^(.+?)(?:txt|\\.txt)\", expand=False).str.strip()\n",
    "df_unicos = df.drop_duplicates(subset=[\"Subpasta\", \"Arquivo_base\"])\n",
    "\n",
    "# === AGRUPAMENTO POR SUBPASTA ===\n",
    "df_grupo = df_unicos.groupby(\"Subpasta\").agg({\n",
    "    \"Arquivo\": \"count\",\n",
    "    \"Tamanho (bytes)\": \"sum\",\n",
    "    \"N¬∫ de linhas\": \"mean\",\n",
    "    \"N¬∫ de caracteres\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "df_grupo = df_grupo.rename(columns={\n",
    "    \"Arquivo\": \"Total de arquivos √∫nicos\",\n",
    "    \"Tamanho (bytes)\": \"Tamanho total (bytes)\",\n",
    "    \"N¬∫ de linhas\": \"M√©dia de linhas\",\n",
    "    \"N¬∫ de caracteres\": \"M√©dia de caracteres\"\n",
    "})\n",
    "\n",
    "# === EXPORTA√á√ÉO ===\n",
    "df_unicos.to_excel(ARQUIVO_UNICOS, index=False)\n",
    "df_grupo.to_excel(ARQUIVO_AGREGADO, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo √∫nico salvo em: {ARQUIVO_UNICOS}\")\n",
    "print(f\"üìä Resumo por subpasta salvo em: {ARQUIVO_AGREGADO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afd0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Corpus unificado salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\corpus_unificado.txt\n"
     ]
    }
   ],
   "source": [
    "####Gera√ß√£o de corpus unificado (`corpus_unificado.txt`)\n",
    "#Ap√≥s as etapas de extra√ß√£o e filtragem dos textos normativos, √© gerado um arquivo final contendo todos os `.txt` limpos, organizados por subpasta e nome de arquivo.\n",
    "# O texto abaixo √© apenas explicativo, n√£o execut√°vel.\n",
    "# Esta etapa permite ao usu√°rio validar rapidamente o corpus unificado, inspecionando o conte√∫do final dos arquivos .txt j√° limpos e organizados.\n",
    "# O arquivo corpus_unificado.txt pode ser aberto em qualquer editor de texto para confer√™ncia visual, busca de termos, ou revis√£o por especialistas.\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "PASTA_CORPUS = Path(r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\")\n",
    "ARQUIVO_SAIDA = PASTA_CORPUS / \"corpus_unificado.txt\"\n",
    "\n",
    "# === UNIFICAR CONTE√öDO ===\n",
    "with open(ARQUIVO_SAIDA, \"w\", encoding=\"utf-8\") as arquivo_saida:\n",
    "    for caminho_txt in PASTA_CORPUS.rglob(\"*.txt\"):\n",
    "        try:\n",
    "            with open(caminho_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "                conteudo = f.read().strip()\n",
    "\n",
    "            if len(conteudo) < 50:\n",
    "                continue  # ignora arquivos muito curtos\n",
    "\n",
    "            nome_arquivo = caminho_txt.name\n",
    "            subpasta = caminho_txt.parent.name\n",
    "\n",
    "            bloco = f\"\\n\\n### Arquivo: {nome_arquivo} | Subpasta: {subpasta}\\n\\n{conteudo}\\n\\n\"\n",
    "            arquivo_saida.write(bloco)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler {caminho_txt.name}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Corpus unificado salvo em: {ARQUIVO_SAIDA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e19876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV salvo com 17640 par√°grafos: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\paragrafos_filtrados_corpus.csv\n",
      "üìä Relat√≥rio salvo: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\relatorio_filtragem_paragrafos.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from openpyxl.cell.cell import ILLEGAL_CHARACTERS_RE\n",
    "\n",
    "# === CAMINHOS ===\n",
    "PASTA = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_ENTRADA = os.path.join(PASTA, \"paragrafos_validos_corpus.csv\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA, \"paragrafos_filtrados_corpus.csv\")\n",
    "ARQUIVO_RELATORIO = os.path.join(PASTA, \"relatorio_filtragem_paragrafos.csv\")\n",
    "\n",
    "# === FILTRO SEM√ÇNTICO COM PROTE√á√ïES R√çGIDAS ===\n",
    "def paragrafo_relevante(texto):\n",
    "    texto_limpo = str(texto).strip()\n",
    "\n",
    "    if len(texto_limpo) > 3000:  # ainda mais seguro\n",
    "        return False\n",
    "    if ILLEGAL_CHARACTERS_RE.search(texto_limpo):\n",
    "        return False\n",
    "\n",
    "    texto_limpo = texto_limpo.lower()\n",
    "    padroes_excluir = [\n",
    "        r'nomes?[:\\-]',\n",
    "        r'e-mail|site:|www\\.',\n",
    "        r'cep:|quadra|srtv|endere',\n",
    "        r'coordena√ß√£o-geral|departamento',\n",
    "        r'minist√©rio da sa√∫de',\n",
    "        r'esta obra.*licen√ßa',\n",
    "        r'(nome|cargo) do autor',\n",
    "        r'sa√∫de p√∫blica brasileira.*acesso',\n",
    "        r'\\b(anexo|ap√™ndice|√≠ndice)\\b',\n",
    "        r'(autores?|vers√£o|tiragem|edi√ß√£o).*202[0-9]',\n",
    "        r'(sigla|significado) de ',\n",
    "        r'(organizador|respons√°vel|revis√£o)',\n",
    "    ]\n",
    "    for padrao in padroes_excluir:\n",
    "        if re.search(padrao, texto_limpo):\n",
    "            return False\n",
    "    if len(texto_limpo.split()) < 6:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# === LEITURA ===\n",
    "df = pd.read_csv(ARQUIVO_ENTRADA)\n",
    "df[\"Relevante\"] = df[\"Par√°grafo\"].astype(str).apply(paragrafo_relevante)\n",
    "\n",
    "# === SEPARA√á√ÉO ===\n",
    "df_filtrado = df[df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "df_excluido = df[~df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "\n",
    "# === SALVAR RESULTADOS EM .CSV ===\n",
    "df_filtrado.to_csv(ARQUIVO_SAIDA, index=False, encoding=\"utf-8\")\n",
    "df_excluido.to_csv(PASTA + \"/paragrafos_descartados.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# === RELAT√ìRIO RESUMIDO ===\n",
    "resumo = pd.DataFrame([{\n",
    "    \"Total original\": len(df),\n",
    "    \"Total mantido\": len(df_filtrado),\n",
    "    \"Total exclu√≠do\": len(df_excluido),\n",
    "    \"% mantido\": round(100 * len(df_filtrado) / len(df), 2),\n",
    "    \"% exclu√≠do\": round(100 * len(df_excluido) / len(df), 2),\n",
    "}])\n",
    "resumo.to_csv(ARQUIVO_RELATORIO, index=False)\n",
    "\n",
    "print(f\"‚úÖ CSV salvo com {len(df_filtrado)} par√°grafos: {ARQUIVO_SAIDA}\")\n",
    "print(f\"üìä Relat√≥rio salvo: {ARQUIVO_RELATORIO}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f12ae1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (4.54.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (4.67.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 992.0/992.0 kB 11.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# === CARREGAR MODELO T5 DE GERA√á√ÉO DE PERGUNTAS ===\u001b[39;00m\n\u001b[32m     18\u001b[39m modelo = \u001b[33m\"\u001b[39m\u001b[33mvalhalla/t5-base-qg-hl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m tokenizer = T5Tokenizer.from_pretrained(modelo)\n\u001b[32m     20\u001b[39m model = T5ForConditionalGeneration.from_pretrained(modelo)\n\u001b[32m     21\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2116\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   2114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m2116\u001b[39m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m._backends)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2102\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   2099\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o dos pacotes necess√°rios\n",
    "%pip install torch transformers tqdm sentencepiece\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURA√á√ïES ===\n",
    "PASTA = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_ENTRADA = os.path.join(PASTA, \"paragrafos_filtrados_corpus.csv\")\n",
    "DATA = datetime.today().strftime('%Y%m%d')\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA, f\"perguntas_geradas_{DATA}.csv\")\n",
    "\n",
    "# === CARREGAR MODELO T5 DE GERA√á√ÉO DE PERGUNTAS ===\n",
    "modelo = \"valhalla/t5-base-qg-hl\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(modelo)\n",
    "model = T5ForConditionalGeneration.from_pretrained(modelo)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# === FUN√á√ÉO PARA GERAR PERGUNTA COM TRATAMENTO DE ERRO ===\n",
    "def gerar_pergunta(texto):\n",
    "    try:\n",
    "        entrada = f\"generate question: {texto}\"\n",
    "        inputs = tokenizer(entrada, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        outputs = model.generate(inputs[\"input_ids\"], max_length=64)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        return f\"[ERRO] {str(e)}\"\n",
    "\n",
    "# === LEITURA DO CSV ===\n",
    "df = pd.read_csv(ARQUIVO_ENTRADA)\n",
    "\n",
    "# (Opcional) limitar para teste:\n",
    "# df = df.head(50)\n",
    "\n",
    "# === GERA√á√ÉO DAS PERGUNTAS COM BARRA DE PROGRESSO ===\n",
    "tqdm.pandas()\n",
    "df[\"Pergunta\"] = df[\"Par√°grafo\"].astype(str).progress_apply(gerar_pergunta)\n",
    "\n",
    "# === SALVAR SA√çDA ===\n",
    "df.to_csv(ARQUIVO_SAIDA, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Perguntas geradas salvas em: {ARQUIVO_SAIDA}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16fefccf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string argument expected, got 'ExpatError'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExpatError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1706\u001b[39m, in \u001b[36mXMLParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1706\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser.Parse(data, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "\u001b[31mExpatError\u001b[39m: not well-formed (invalid token): line 1, column 7209623",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mParseError\u001b[39m                                Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# === CARGA DE PAR√ÅGRAFOS ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m df = pd.read_excel(ARQUIVO_PARAGRAFOS)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# === GERAR PERGUNTAS POR PAR√ÅGRAFO ===\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = io.parse(\n\u001b[32m    509\u001b[39m         sheet_name=sheet_name,\n\u001b[32m    510\u001b[39m         header=header,\n\u001b[32m    511\u001b[39m         names=names,\n\u001b[32m    512\u001b[39m         index_col=index_col,\n\u001b[32m    513\u001b[39m         usecols=usecols,\n\u001b[32m    514\u001b[39m         dtype=dtype,\n\u001b[32m    515\u001b[39m         converters=converters,\n\u001b[32m    516\u001b[39m         true_values=true_values,\n\u001b[32m    517\u001b[39m         false_values=false_values,\n\u001b[32m    518\u001b[39m         skiprows=skiprows,\n\u001b[32m    519\u001b[39m         nrows=nrows,\n\u001b[32m    520\u001b[39m         na_values=na_values,\n\u001b[32m    521\u001b[39m         keep_default_na=keep_default_na,\n\u001b[32m    522\u001b[39m         na_filter=na_filter,\n\u001b[32m    523\u001b[39m         verbose=verbose,\n\u001b[32m    524\u001b[39m         parse_dates=parse_dates,\n\u001b[32m    525\u001b[39m         date_parser=date_parser,\n\u001b[32m    526\u001b[39m         date_format=date_format,\n\u001b[32m    527\u001b[39m         thousands=thousands,\n\u001b[32m    528\u001b[39m         decimal=decimal,\n\u001b[32m    529\u001b[39m         comment=comment,\n\u001b[32m    530\u001b[39m         skipfooter=skipfooter,\n\u001b[32m    531\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    532\u001b[39m     )\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03mParse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m>>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reader.parse(\n\u001b[32m   1617\u001b[39m     sheet_name=sheet_name,\n\u001b[32m   1618\u001b[39m     header=header,\n\u001b[32m   1619\u001b[39m     names=names,\n\u001b[32m   1620\u001b[39m     index_col=index_col,\n\u001b[32m   1621\u001b[39m     usecols=usecols,\n\u001b[32m   1622\u001b[39m     converters=converters,\n\u001b[32m   1623\u001b[39m     true_values=true_values,\n\u001b[32m   1624\u001b[39m     false_values=false_values,\n\u001b[32m   1625\u001b[39m     skiprows=skiprows,\n\u001b[32m   1626\u001b[39m     nrows=nrows,\n\u001b[32m   1627\u001b[39m     na_values=na_values,\n\u001b[32m   1628\u001b[39m     parse_dates=parse_dates,\n\u001b[32m   1629\u001b[39m     date_parser=date_parser,\n\u001b[32m   1630\u001b[39m     date_format=date_format,\n\u001b[32m   1631\u001b[39m     thousands=thousands,\n\u001b[32m   1632\u001b[39m     comment=comment,\n\u001b[32m   1633\u001b[39m     skipfooter=skipfooter,\n\u001b[32m   1634\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1635\u001b[39m     **kwds,\n\u001b[32m   1636\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    777\u001b[39m file_rows_needed = \u001b[38;5;28mself\u001b[39m._calc_rows(header, index_col, skiprows, nrows)\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m data = \u001b[38;5;28mself\u001b[39m.get_sheet_data(sheet, file_rows_needed)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    780\u001b[39m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_data\u001b[39m\u001b[34m(self, sheet, file_rows_needed)\u001b[39m\n\u001b[32m    614\u001b[39m last_row_with_data = -\u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet.rows):\n\u001b[32m    616\u001b[39m     converted_row = [\u001b[38;5;28mself\u001b[39m._convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[39m, in \u001b[36mReadOnlyWorksheet._cells_by_row\u001b[39m\u001b[34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[39m\n\u001b[32m     78\u001b[39m parser = WorkSheetParser(src,\n\u001b[32m     79\u001b[39m                          \u001b[38;5;28mself\u001b[39m._shared_strings,\n\u001b[32m     80\u001b[39m                          data_only=\u001b[38;5;28mself\u001b[39m.parent.data_only,\n\u001b[32m     81\u001b[39m                          epoch=\u001b[38;5;28mself\u001b[39m.parent.epoch,\n\u001b[32m     82\u001b[39m                          date_formats=\u001b[38;5;28mself\u001b[39m.parent._date_formats,\n\u001b[32m     83\u001b[39m                          timedelta_formats=\u001b[38;5;28mself\u001b[39m.parent._timedelta_formats)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser.parse():\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx > max_row:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[39m, in \u001b[36mWorkSheetParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    154\u001b[39m it = iterparse(\u001b[38;5;28mself\u001b[39m.source) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, element \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[32m    157\u001b[39m     tag_name = element.tag\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1236\u001b[39m, in \u001b[36miterparse.<locals>.iterator\u001b[39m\u001b[34m(source)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1236\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m pullparser.read_events()\n\u001b[32m   1237\u001b[39m     \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1312\u001b[39m, in \u001b[36mXMLPullParser.read_events\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m event\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1284\u001b[39m, in \u001b[36mXMLPullParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     \u001b[38;5;28mself\u001b[39m._parser.feed(data)\n\u001b[32m   1285\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1708\u001b[39m, in \u001b[36mXMLParser.feed\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[32m-> \u001b[39m\u001b[32m1708\u001b[39m     \u001b[38;5;28mself\u001b[39m._raiseerror(v)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\xml\\etree\\ElementTree.py:1615\u001b[39m, in \u001b[36mXMLParser._raiseerror\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   1614\u001b[39m err.position = value.lineno, value.offset\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[31mParseError\u001b[39m: not well-formed (invalid token): line 1, column 7209623 (<string>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2146\u001b[39m, in \u001b[36mInteractiveShell.showtraceback\u001b[39m\u001b[34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[39m\n\u001b[32m   2141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(etype, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n\u001b[32m   2144\u001b[39m     \u001b[38;5;66;03m# Though this won't be called by syntax errors in the input\u001b[39;00m\n\u001b[32m   2145\u001b[39m     \u001b[38;5;66;03m# line, there may be SyntaxError cases with imported code.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2146\u001b[39m     \u001b[38;5;28mself\u001b[39m.showsyntaxerror(filename, running_compiled_code)\n\u001b[32m   2147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m UsageError:\n\u001b[32m   2148\u001b[39m     \u001b[38;5;28mself\u001b[39m.show_usage_error(value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2236\u001b[39m, in \u001b[36mInteractiveShell.showsyntaxerror\u001b[39m\u001b[34m(self, filename, running_compiled_code)\u001b[39m\n\u001b[32m   2234\u001b[39m \u001b[38;5;66;03m# If the error occurred when executing compiled code, we should provide full stacktrace.\u001b[39;00m\n\u001b[32m   2235\u001b[39m elist = traceback.extract_tb(last_traceback) \u001b[38;5;28;01mif\u001b[39;00m running_compiled_code \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m stb = \u001b[38;5;28mself\u001b[39m.SyntaxTB.structured_traceback(etype, value, elist)\n\u001b[32m   2237\u001b[39m \u001b[38;5;28mself\u001b[39m._showtraceback(etype, value, stb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:1240\u001b[39m, in \u001b[36mSyntaxTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1238\u001b[39m         value.text = newtext\n\u001b[32m   1239\u001b[39m \u001b[38;5;28mself\u001b[39m.last_syntax_error = value\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SyntaxTB, \u001b[38;5;28mself\u001b[39m).structured_traceback(\n\u001b[32m   1241\u001b[39m     etype, value, etb, tb_offset=tb_offset, context=context\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:212\u001b[39m, in \u001b[36mListTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    210\u001b[39m     out_list.extend(\u001b[38;5;28mself\u001b[39m._format_list(elist))\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# The exception info should be a single entry in the list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m lines = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._format_exception_only(etype, evalue))\n\u001b[32m    213\u001b[39m out_list.append(lines)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Find chained exceptions if we have a traceback (not for exception-only mode)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:374\u001b[39m, in \u001b[36mListTB._format_exception_only\u001b[39m\u001b[34m(self, etype, value)\u001b[39m\n\u001b[32m    371\u001b[39m     s = \u001b[38;5;28mself\u001b[39m._some_str(value)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s:\n\u001b[32m    373\u001b[39m     output_list.append(\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    375\u001b[39m             stype_tokens\n\u001b[32m    376\u001b[39m             + [\n\u001b[32m    377\u001b[39m                 (Token.ExcName, \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    378\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    379\u001b[39m                 (Token, s),\n\u001b[32m    380\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m    381\u001b[39m             ]\n\u001b[32m    382\u001b[39m         )\n\u001b[32m    383\u001b[39m     )\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     output_list.append(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % stype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\utils\\PyColorize.py:66\u001b[39m, in \u001b[36mTheme.format\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: TokenStream) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pygments.format(stream, \u001b[38;5;28mself\u001b[39m._formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     formatter.format(tokens, realoutfile)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Formatter.format(\u001b[38;5;28mself\u001b[39m, tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_unencoded(tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:286\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# outfile.write( '!' + str(ottype) + '->' + str(ttype) + '!' )\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_found:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         outfile.write(value)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    289\u001b[39m     outfile.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string argument expected, got 'ExpatError'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string argument expected, got 'ExpatError'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3381\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3377\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3379\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3381\u001b[39m         \u001b[38;5;28mself\u001b[39m._format_exception_for_storage(result.error_in_exec)\n\u001b[32m   3382\u001b[39m     )\n\u001b[32m   3384\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3385\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3410\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3408\u001b[39m     \u001b[38;5;66;03m# Extract traceback if the error happened during compiled code execution\u001b[39;00m\n\u001b[32m   3409\u001b[39m     elist = traceback.extract_tb(tb) \u001b[38;5;28;01mif\u001b[39;00m running_compiled_code \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     stb = \u001b[38;5;28mself\u001b[39m.SyntaxTB.structured_traceback(etype, evalue, elist)\n\u001b[32m   3412\u001b[39m \u001b[38;5;66;03m# Handle UsageError with a simple message\u001b[39;00m\n\u001b[32m   3413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m UsageError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:1240\u001b[39m, in \u001b[36mSyntaxTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1238\u001b[39m         value.text = newtext\n\u001b[32m   1239\u001b[39m \u001b[38;5;28mself\u001b[39m.last_syntax_error = value\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SyntaxTB, \u001b[38;5;28mself\u001b[39m).structured_traceback(\n\u001b[32m   1241\u001b[39m     etype, value, etb, tb_offset=tb_offset, context=context\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:212\u001b[39m, in \u001b[36mListTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    210\u001b[39m     out_list.extend(\u001b[38;5;28mself\u001b[39m._format_list(elist))\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# The exception info should be a single entry in the list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m lines = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._format_exception_only(etype, evalue))\n\u001b[32m    213\u001b[39m out_list.append(lines)\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Find chained exceptions if we have a traceback (not for exception-only mode)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\core\\ultratb.py:374\u001b[39m, in \u001b[36mListTB._format_exception_only\u001b[39m\u001b[34m(self, etype, value)\u001b[39m\n\u001b[32m    371\u001b[39m     s = \u001b[38;5;28mself\u001b[39m._some_str(value)\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s:\n\u001b[32m    373\u001b[39m     output_list.append(\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    375\u001b[39m             stype_tokens\n\u001b[32m    376\u001b[39m             + [\n\u001b[32m    377\u001b[39m                 (Token.ExcName, \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    378\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    379\u001b[39m                 (Token, s),\n\u001b[32m    380\u001b[39m                 (Token, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m    381\u001b[39m             ]\n\u001b[32m    382\u001b[39m         )\n\u001b[32m    383\u001b[39m     )\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     output_list.append(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % stype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\IPython\\utils\\PyColorize.py:66\u001b[39m, in \u001b[36mTheme.format\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: TokenStream) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pygments.format(stream, \u001b[38;5;28mself\u001b[39m._formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     formatter.format(tokens, realoutfile)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Formatter.format(\u001b[38;5;28mself\u001b[39m, tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_unencoded(tokensource, outfile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pygments\\formatters\\terminal256.py:286\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# outfile.write( '!' + str(ottype) + '->' + str(ttype) + '!' )\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_found:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         outfile.write(value)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    289\u001b[39m     outfile.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string argument expected, got 'ExpatError'"
     ]
    }
   ],
   "source": [
    "#filtro_paragrafos_relevantes Filtra semanticamente os par√°grafos\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# === CAMINHOS ===\n",
    "PASTA_CORPUS = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_PARAGRAFOS = os.path.join(PASTA_CORPUS, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA_CORPUS, f\"perguntas_geradas_{datetime.today().strftime('%Y%m%d')}.xlsx\")\n",
    "\n",
    "# === FUN√á√ÉO PARA GERAR PERGUNTAS COMUNS ===\n",
    "def gerar_perguntas(texto):\n",
    "    perguntas = []\n",
    "\n",
    "    # Baixo n√≠vel de NLP, apenas heur√≠stico (foco em utilidade pr√°tica)\n",
    "    if re.search(r\"\\bprocedimento[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o os procedimentos recomendados?\")\n",
    "    if re.search(r\"\\bexame[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Como √© realizado o exame?\")\n",
    "    if re.search(r\"\\btratamento\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Qual √© o tratamento indicado?\")\n",
    "    if re.search(r\"\\bnotifica(√ß√£o|r)\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quando o caso deve ser notificado?\")\n",
    "    if re.search(r\"\\bmedicamento[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais medicamentos devem ser utilizados?\")\n",
    "    if re.search(r\"\\bsintoma[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o os sintomas?\")\n",
    "    if re.search(r\"\\bmonitoramento\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Como √© feito o monitoramento?\")\n",
    "    if re.search(r\"\\bvigil√¢ncia\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o as a√ß√µes de vigil√¢ncia indicadas?\")\n",
    "    if re.search(r\"\\bsurto[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"O que deve ser feito em caso de surto?\")\n",
    "\n",
    "    return perguntas\n",
    "\n",
    "# === CARGA DE PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS)\n",
    "\n",
    "# === GERAR PERGUNTAS POR PAR√ÅGRAFO ===\n",
    "linhas_saida = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    arquivo = row[\"Arquivo\"]\n",
    "    texto = str(row[\"Texto\"])\n",
    "    perguntas = gerar_perguntas(texto)\n",
    "\n",
    "    for pergunta in perguntas:\n",
    "        linhas_saida.append({\n",
    "            \"Arquivo (Tema)\": arquivo,\n",
    "            \"Pergunta sugerida\": pergunta,\n",
    "            \"Texto de origem\": texto\n",
    "        })\n",
    "\n",
    "# === SALVAR RESULTADO ===\n",
    "df_resultado = pd.DataFrame(linhas_saida)\n",
    "df_resultado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_SAIDA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7404762",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === TESTE COM AMOSTRA DE 100 PAR√ÅGRAFOS ===\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = pd.read_excel(ARQUIVO_PARAGRAFOS).sample(\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\generic.py:6137\u001b[39m, in \u001b[36mNDFrame.sample\u001b[39m\u001b[34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[39m\n\u001b[32m   6134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6135\u001b[39m     weights = sample.preprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[32m-> \u001b[39m\u001b[32m6137\u001b[39m sampled_indices = sample.sample(obj_len, size, replace, weights, rs)\n\u001b[32m   6138\u001b[39m result = \u001b[38;5;28mself\u001b[39m.take(sampled_indices, axis=axis)\n\u001b[32m   6140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\sample.py:152\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(obj_len, size, replace, weights, random_state)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid weights: weights sum to zero\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m random_state.choice(obj_len, size=size, replace=replace, p=weights).astype(\n\u001b[32m    153\u001b[39m     np.intp, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    154\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:1020\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# === TESTE COM AMOSTRA DE 100 PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec05019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Arquivo  \\\n",
      "0   adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "1   adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "2   adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "3   adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "4   adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "..                                   ...   \n",
      "95  adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "96  adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "97  adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "98  adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "99  adenovirus_guia_1txt_guiavsa2023.txt   \n",
      "\n",
      "                                            Par√°grafo  N√∫mero do par√°grafo  \\\n",
      "0   1 VIGIL√ÇNCIA INTEGRADA DA COVID-19, INFLUENZA ...                    1   \n",
      "1   Diversas fam√≠lias de v√≠rus respirat√≥rios est√£o...                    2   \n",
      "2   Os v√≠rus influenza, v√≠rus sincicial respirat√≥r...                    3   \n",
      "3   A vigil√¢ncia de influenza foi implantada em 20...                    4   \n",
      "4   Pela caracter√≠stica sindr√¥mica da doen√ßa, outr...                    5   \n",
      "..                                                ...                  ...   \n",
      "95  Devido √† import√¢ncia da prote√≠na S do coronav√≠...                   96   \n",
      "96  Em janeiro de 2021, a OMS coordenou um estudo ...                   97   \n",
      "97  Apesar de ter discutido os poss√≠veis cen√°rios ...                   98   \n",
      "98  Dessa forma, at√© a publica√ß√£o deste documento,...                   99   \n",
      "99  No entanto, a transmissibilidade do v√≠rus depe...                  100   \n",
      "\n",
      "    Relevante  \n",
      "0       False  \n",
      "1        True  \n",
      "2        True  \n",
      "3        True  \n",
      "4        True  \n",
      "..        ...  \n",
      "95       True  \n",
      "96       True  \n",
      "97       True  \n",
      "98       True  \n",
      "99       True  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 44\n"
     ]
    }
   ],
   "source": [
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e81d4a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando perguntas - Amostra: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20106/20106 [00:00<00:00, 40881.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Perguntas da amostra geradas com sucesso!\n",
      "üìÑ Arquivo salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\perguntas_amostra.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#gerador_perguntas_t5\n",
    "# === CONTINUAR AQUI COM O MESMO SCRIPT ===\n",
    "linhas = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Gerando perguntas - Amostra\"):\n",
    "    texto = str(row.get(\"Texto\", \"\")).strip()\n",
    "    if not texto:\n",
    "        continue\n",
    "    try:\n",
    "        perguntas = gerar_perguntas_t5(texto)\n",
    "        for pergunta in perguntas:\n",
    "            linhas.append({\n",
    "                \"Arquivo (Tema)\": row.get(\"Arquivo\", \"\"),\n",
    "                \"Pergunta sugerida\": pergunta,\n",
    "                \"Texto de origem\": texto\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro na linha {idx}: {e}\")\n",
    "\n",
    "# === SALVAR RESULTADO FINAL ===\n",
    "ARQUIVO_TESTE = os.path.join(PASTA_CORPUS, \"perguntas_amostra.xlsx\")\n",
    "df_resultado = pd.DataFrame(linhas)\n",
    "df_resultado.to_excel(ARQUIVO_TESTE, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas da amostra geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_TESTE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8da234c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (4.54.1)\n",
      "Requirement already satisfied: torch in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# === CARREGAR MODELO E TOKENIZER ===\u001b[39;00m\n\u001b[32m     18\u001b[39m MODELO = \u001b[33m\"\u001b[39m\u001b[33mvalhalla/t5-base-qg-hl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m tokenizer = T5Tokenizer.from_pretrained(MODELO)\n\u001b[32m     20\u001b[39m model = T5ForConditionalGeneration.from_pretrained(MODELO)\n\u001b[32m     21\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2116\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   2114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m2116\u001b[39m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m._backends)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isisi\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2102\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   2099\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   2101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o dos pacotes necess√°rios (pode deixar s√≥ na primeira c√©lula do notebook)\n",
    "%pip install transformers torch pandas openpyxl tqdm sentencepiece\n",
    "\n",
    "# === IMPORTA√á√ïES ===\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === CONFIGURA√á√ÉO DE CAMINHOS ===\n",
    "PASTA_CORPUS = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_PARAGRAFOS = os.path.join(PASTA_CORPUS, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA_CORPUS, f\"perguntas_avancadas_{datetime.today().strftime('%Y%m%d')}.xlsx\")\n",
    "\n",
    "# === CARREGAR MODELO E TOKENIZER ===\n",
    "MODELO = \"valhalla/t5-base-qg-hl\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODELO)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODELO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# === FUN√á√ÉO DE GERA√á√ÉO DE PERGUNTAS ===\n",
    "def gerar_perguntas_t5(texto):\n",
    "    entrada = f\"generate question: {texto} </s>\"\n",
    "    input_ids = tokenizer.encode(entrada, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():  # otimiza uso de mem√≥ria\n",
    "        saida_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=64,\n",
    "            num_beams=4,\n",
    "            num_return_sequences=3,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    perguntas = [tokenizer.decode(g, skip_special_tokens=True) for g in saida_ids]\n",
    "    return list(set(perguntas))  # remove duplicadas\n",
    "\n",
    "# === CARREGAR PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS)\n",
    "linhas = []\n",
    "\n",
    "# === PERCORRER PAR√ÅGRAFOS COM BARRA DE PROGRESSO ===\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Gerando perguntas\"):\n",
    "    texto = str(row.get(\"Texto\", \"\")).strip()\n",
    "    if not texto:\n",
    "        continue\n",
    "    try:\n",
    "        perguntas = gerar_perguntas_t5(texto)\n",
    "        for pergunta in perguntas:\n",
    "            linhas.append({\n",
    "                \"Arquivo (Tema)\": row.get(\"Arquivo\", \"\"),\n",
    "                \"Pergunta sugerida\": pergunta,\n",
    "                \"Texto de origem\": texto\n",
    "            })\n",
    "        # Checkpoint: salva a cada 100 par√°grafos\n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            pd.DataFrame(linhas).to_excel(ARQUIVO_SAIDA, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro na linha {idx}: {e}\")\n",
    "\n",
    "# === SALVAR RESULTADO FINAL ===\n",
    "df_resultado = pd.DataFrame(linhas)\n",
    "df_resultado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_SAIDA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
