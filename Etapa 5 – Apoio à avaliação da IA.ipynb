{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd292b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Lendo arquivo...\n",
      "‚öôÔ∏è Aplicando filtro sem√¢ntico...\n",
      "‚úÖ Par√°grafos mantidos: 574153\n",
      "üö´ Par√°grafos exclu√≠dos: 50769\n",
      "üíæ Salvando arquivo com par√°grafos filtrados...\n",
      "üìù Gerando relat√≥rio...\n",
      "üìä Relat√≥rio salvo com sucesso!\n",
      "üìÅ Arquivo filtrado: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\paragrafos_filtrados_corpus.xlsx\n",
      "üìÑ Relat√≥rio: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\relatorio_filtragem_paragrafos.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# === CONFIGURA√á√ïES DE CAMINHO ===\n",
    "PASTA = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_ENTRADA = os.path.join(PASTA, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA, \"paragrafos_filtrados_corpus.xlsx\")\n",
    "ARQUIVO_RELATORIO = os.path.join(PASTA, \"relatorio_filtragem_paragrafos.xlsx\")\n",
    "\n",
    "# === FUN√á√ÉO DE FILTRAGEM ===\n",
    "def paragrafo_relevante(texto):\n",
    "    texto_limpo = texto.lower().strip()\n",
    "    padroes_excluir = [\n",
    "        r'nomes?[:\\-]',\n",
    "        r'e-mail|site:|www\\.',\n",
    "        r'cep:|quadra|srtv|endere',\n",
    "        r'coordena√ß√£o-geral|departamento',\n",
    "        r'minist√©rio da sa√∫de',\n",
    "        r'esta obra.*licen√ßa',\n",
    "        r'(nome|cargo) do autor',\n",
    "        r'sa√∫de p√∫blica brasileira.*acesso',\n",
    "        r'\\b(anexo|ap√™ndice|√≠ndice)\\b',\n",
    "        r'(autores?|vers√£o|tiragem|edi√ß√£o).*202[0-9]',\n",
    "        r'(sigla|significado) de ',\n",
    "        r'(organizador|respons√°vel|revis√£o)',\n",
    "    ]\n",
    "    for padrao in padroes_excluir:\n",
    "        if re.search(padrao, texto_limpo):\n",
    "            return False\n",
    "    if len(texto_limpo.split()) < 6:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# === EXECU√á√ÉO ===\n",
    "print(\"üîç Lendo arquivo...\")\n",
    "df = pd.read_excel(ARQUIVO_ENTRADA)\n",
    "\n",
    "print(\"‚öôÔ∏è Aplicando filtro sem√¢ntico...\")\n",
    "df[\"Relevante\"] = df[\"Texto\"].astype(str).apply(paragrafo_relevante)\n",
    "\n",
    "df_filtrado = df[df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "df_excluido = df[~df[\"Relevante\"]].drop(columns=[\"Relevante\"])\n",
    "\n",
    "print(f\"‚úÖ Par√°grafos mantidos: {len(df_filtrado)}\")\n",
    "print(f\"üö´ Par√°grafos exclu√≠dos: {len(df_excluido)}\")\n",
    "\n",
    "# === SALVAR RESULTADO FILTRADO ===\n",
    "print(\"üíæ Salvando arquivo com par√°grafos filtrados...\")\n",
    "df_filtrado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "# === GERAR RELAT√ìRIO EM EXCEL COM AMOSTRAS ===\n",
    "print(\"üìù Gerando relat√≥rio...\")\n",
    "resumo = {\n",
    "    \"Total original\": [len(df)],\n",
    "    \"Total mantido\": [len(df_filtrado)],\n",
    "    \"Total exclu√≠do\": [len(df_excluido)],\n",
    "    \"% mantido\": [round(100 * len(df_filtrado) / len(df), 2)],\n",
    "    \"% exclu√≠do\": [round(100 * len(df_excluido) / len(df), 2)],\n",
    "}\n",
    "df_resumo = pd.DataFrame(resumo)\n",
    "\n",
    "amostra_mantido = df_filtrado.sample(min(5, len(df_filtrado)), random_state=1)\n",
    "amostra_excluido = df_excluido.sample(min(5, len(df_excluido)), random_state=1)\n",
    "\n",
    "with pd.ExcelWriter(ARQUIVO_RELATORIO) as writer:\n",
    "    df_resumo.to_excel(writer, sheet_name=\"Resumo\", index=False)\n",
    "    amostra_mantido.to_excel(writer, sheet_name=\"Amostra Mantido\", index=False)\n",
    "    amostra_excluido.to_excel(writer, sheet_name=\"Amostra Exclu√≠do\", index=False)\n",
    "\n",
    "print(\"üìä Relat√≥rio salvo com sucesso!\")\n",
    "print(f\"üìÅ Arquivo filtrado: {ARQUIVO_SAIDA}\")\n",
    "print(f\"üìÑ Relat√≥rio: {ARQUIVO_RELATORIO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef747724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnosticar_pasta Antes da Etapa 2 ‚Äì Extra√ß√£o e limpeza de texto Diagn√≥stico visual de duplicados e nomes corrompidos\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "\n",
    "# === FUN√á√ïES AUXILIARES ===\n",
    "\n",
    "def calcular_hash(caminho_arquivo, limite=1024*1024):\n",
    "    \"\"\"Calcula hash de uma parte do arquivo (1 MB por padr√£o) para diagn√≥stico r√°pido.\"\"\"\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(caminho_arquivo, 'rb') as f:\n",
    "        sha256.update(f.read(limite))\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "def normalizar_nome(nome):\n",
    "    \"\"\"Remove repeti√ß√µes consecutivas de sufixos.\"\"\"\n",
    "    padrao = r'(txt_\\w+\\d{4})+'\n",
    "    return re.sub(padrao, lambda m: m.group(1), nome)\n",
    "\n",
    "def diagnosticar_pasta(pasta_raiz, saida_texto):\n",
    "    pasta_raiz = Path(pasta_raiz)\n",
    "    hash_map = {}\n",
    "    log_linhas = []\n",
    "    log_path = pasta_raiz / \"log_diagnostico.csv\"\n",
    "\n",
    "    saida_texto.insert(tk.END, f\"üîç Diagn√≥stico em: {pasta_raiz}\\n\")\n",
    "    saida_texto.insert(tk.END, \"Apenas leitura ‚Äî nenhum arquivo ser√° alterado.\\n\\n\")\n",
    "    saida_texto.update()\n",
    "\n",
    "    for caminho_arquivo in pasta_raiz.rglob(\"*.txt\"):\n",
    "        hash_arquivo = calcular_hash(caminho_arquivo)\n",
    "        nome_original = caminho_arquivo.name\n",
    "        caminho_pasta = caminho_arquivo.parent\n",
    "\n",
    "        # Verifica duplicidade de conte√∫do\n",
    "        if hash_arquivo in hash_map:\n",
    "            saida_texto.insert(tk.END, f\"‚ö†Ô∏è Poss√≠vel duplicado: {nome_original} (igual a {hash_map[hash_arquivo].name})\\n\")\n",
    "            log_linhas.append([\"DUPLICADO\", str(caminho_arquivo), \"Mesma hash de\", str(hash_map[hash_arquivo])])\n",
    "        else:\n",
    "            hash_map[hash_arquivo] = caminho_arquivo\n",
    "\n",
    "        # Verifica nome corrompido\n",
    "        nome_corrigido = normalizar_nome(nome_original)\n",
    "        if nome_corrigido != nome_original:\n",
    "            saida_texto.insert(tk.END, f\"üîÅ Nome suspeito: {nome_original} ‚Üí Sugerido: {nome_corrigido}\\n\")\n",
    "            log_linhas.append([\"NOME_CORROMPIDO\", str(caminho_arquivo), \"Sugerido\", nome_corrigido])\n",
    "\n",
    "    with open(log_path, mode='w', newline='', encoding='utf-8') as log_csv:\n",
    "        writer = csv.writer(log_csv)\n",
    "        writer.writerow([\"Tipo\", \"Arquivo\", \"Info\", \"Refer√™ncia/Sugest√£o\"])\n",
    "        writer.writerows(log_linhas)\n",
    "\n",
    "    saida_texto.insert(tk.END, f\"\\nüìÑ Log salvo em: {log_path}\\n\")\n",
    "    saida_texto.insert(tk.END, \"‚úÖ Diagn√≥stico conclu√≠do.\\n\")\n",
    "    saida_texto.update()\n",
    "\n",
    "# === INTERFACE GR√ÅFICA ===\n",
    "\n",
    "def iniciar_interface():\n",
    "    def escolher_pasta():\n",
    "        pasta = filedialog.askdirectory(title=\"Selecione a pasta 'corpus_final'\")\n",
    "        if pasta:\n",
    "            entrada_pasta.delete(0, tk.END)\n",
    "            entrada_pasta.insert(0, pasta)\n",
    "\n",
    "    def executar_diagnostico():\n",
    "        pasta_escolhida = entrada_pasta.get()\n",
    "        if not os.path.isdir(pasta_escolhida):\n",
    "            messagebox.showerror(\"Erro\", \"Selecione uma pasta v√°lida.\")\n",
    "            return\n",
    "        saida_texto.delete(1.0, tk.END)\n",
    "        diagnosticar_pasta(pasta_escolhida, saida_texto)\n",
    "\n",
    "    janela = tk.Tk()\n",
    "    janela.title(\"üîé Diagn√≥stico de Arquivos Duplicados e Nomes Corrompidos\")\n",
    "\n",
    "    tk.Label(janela, text=\"üìÅ Pasta Base:\").pack(pady=5)\n",
    "    entrada_pasta = tk.Entry(janela, width=60)\n",
    "    entrada_pasta.pack()\n",
    "    tk.Button(janela, text=\"Selecionar Pasta\", command=escolher_pasta).pack(pady=5)\n",
    "\n",
    "    tk.Button(janela, text=\"üîç Executar Diagn√≥stico\", command=executar_diagnostico, bg=\"blue\", fg=\"white\").pack(pady=10)\n",
    "\n",
    "    saida_texto = scrolledtext.ScrolledText(janela, width=100, height=25)\n",
    "    saida_texto.pack(padx=10, pady=10)\n",
    "\n",
    "    janela.mainloop()\n",
    "\n",
    "# Rodar\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc55887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Execu√ß√£o conclu√≠da. Log salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\log_execucao.csv\n"
     ]
    }
   ],
   "source": [
    "#executar_log_diagnostico remove duplicatas reais e renomeia arquivos com nome corrompido.Logo ap√≥s o diagn√≥stico, ainda na Etapa 2\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURA√á√ÉO ===\n",
    "PASTA_BASE = Path(r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\")  # ajuste se necess√°rio\n",
    "CAMINHO_LOG_DIAGNOSTICO = PASTA_BASE / \"log_diagnostico.csv\"\n",
    "CAMINHO_LOG_EXECUCAO = PASTA_BASE / \"log_execucao.csv\"\n",
    "\n",
    "# === LEITURA DO LOG ===\n",
    "with open(CAMINHO_LOG_DIAGNOSTICO, encoding='utf-8') as f:\n",
    "    leitor = csv.DictReader(f)\n",
    "    acoes = list(leitor)\n",
    "\n",
    "# === EXECU√á√ÉO DAS A√á√ïES ===\n",
    "log_execucao = []\n",
    "\n",
    "for linha in acoes:\n",
    "    tipo = linha['Tipo']\n",
    "    caminho_str = linha['Arquivo']\n",
    "    caminho_arquivo = Path(caminho_str)\n",
    "\n",
    "    if not caminho_arquivo.exists():\n",
    "        log_execucao.append([\"IGNORADO\", caminho_str, \"Arquivo n√£o encontrado\"])\n",
    "        continue\n",
    "\n",
    "    if tipo == \"DUPLICADO\":\n",
    "        try:\n",
    "            caminho_arquivo.unlink()\n",
    "            log_execucao.append([\"REMOVIDO\", caminho_str, \"Duplicata removida\"])\n",
    "            print(f\"üóëÔ∏è Removido: {caminho_str}\")\n",
    "        except Exception as e:\n",
    "            log_execucao.append([\"ERRO\", caminho_str, f\"Erro ao remover: {e}\"])\n",
    "\n",
    "    elif tipo == \"NOME_CORROMPIDO\":\n",
    "        sugestao = linha['Refer√™ncia/Sugest√£o']\n",
    "        novo_caminho = caminho_arquivo.parent / sugestao\n",
    "        contador = 1\n",
    "        while novo_caminho.exists():\n",
    "            novo_caminho = caminho_arquivo.parent / f\"{sugestao}_{contador}.txt\"\n",
    "            contador += 1\n",
    "        try:\n",
    "            caminho_arquivo.rename(novo_caminho)\n",
    "            log_execucao.append([\"RENOMEADO\", caminho_str, f\"Novo nome: {novo_caminho.name}\"])\n",
    "            print(f\"‚úèÔ∏è Renomeado: {caminho_arquivo.name} ‚Üí {novo_caminho.name}\")\n",
    "        except Exception as e:\n",
    "            log_execucao.append([\"ERRO\", caminho_str, f\"Erro ao renomear: {e}\"])\n",
    "\n",
    "# === SALVA LOG FINAL ===\n",
    "with open(CAMINHO_LOG_EXECUCAO, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"A√ß√£o\", \"Arquivo\", \"Detalhes\"])\n",
    "    writer.writerows(log_execucao)\n",
    "\n",
    "print(f\"\\n‚úÖ Execu√ß√£o conclu√≠da. Log salvo em: {CAMINHO_LOG_EXECUCAO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fefccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Perguntas geradas com sucesso!\n",
      "üìÑ Arquivo salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\perguntas_geradas_20250802.xlsx\n"
     ]
    }
   ],
   "source": [
    "#filtro_paragrafos_relevantes Filtra semanticamente os par√°grafos\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# === CAMINHOS ===\n",
    "PASTA_CORPUS = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_PARAGRAFOS = os.path.join(PASTA_CORPUS, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA_CORPUS, f\"perguntas_geradas_{datetime.today().strftime('%Y%m%d')}.xlsx\")\n",
    "\n",
    "# === FUN√á√ÉO PARA GERAR PERGUNTAS COMUNS ===\n",
    "def gerar_perguntas(texto):\n",
    "    perguntas = []\n",
    "\n",
    "    # Baixo n√≠vel de NLP, apenas heur√≠stico (foco em utilidade pr√°tica)\n",
    "    if re.search(r\"\\bprocedimento[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o os procedimentos recomendados?\")\n",
    "    if re.search(r\"\\bexame[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Como √© realizado o exame?\")\n",
    "    if re.search(r\"\\btratamento\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Qual √© o tratamento indicado?\")\n",
    "    if re.search(r\"\\bnotifica(√ß√£o|r)\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quando o caso deve ser notificado?\")\n",
    "    if re.search(r\"\\bmedicamento[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais medicamentos devem ser utilizados?\")\n",
    "    if re.search(r\"\\bsintoma[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o os sintomas?\")\n",
    "    if re.search(r\"\\bmonitoramento\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Como √© feito o monitoramento?\")\n",
    "    if re.search(r\"\\bvigil√¢ncia\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"Quais s√£o as a√ß√µes de vigil√¢ncia indicadas?\")\n",
    "    if re.search(r\"\\bsurto[s]?\\b\", texto, re.IGNORECASE):\n",
    "        perguntas.append(\"O que deve ser feito em caso de surto?\")\n",
    "\n",
    "    return perguntas\n",
    "\n",
    "# === CARGA DE PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS)\n",
    "\n",
    "# === GERAR PERGUNTAS POR PAR√ÅGRAFO ===\n",
    "linhas_saida = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    arquivo = row[\"Arquivo\"]\n",
    "    texto = str(row[\"Texto\"])\n",
    "    perguntas = gerar_perguntas(texto)\n",
    "\n",
    "    for pergunta in perguntas:\n",
    "        linhas_saida.append({\n",
    "            \"Arquivo (Tema)\": arquivo,\n",
    "            \"Pergunta sugerida\": pergunta,\n",
    "            \"Texto de origem\": texto\n",
    "        })\n",
    "\n",
    "# === SALVAR RESULTADO ===\n",
    "df_resultado = pd.DataFrame(linhas_saida)\n",
    "df_resultado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_SAIDA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7404762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TESTE COM AMOSTRA DE 100 PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec05019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Arquivo  Par√°grafo n¬∫  \\\n",
      "346681  metapneumovirus_guia_1txt_guiavsa2023txt_guiav...          1576   \n",
      "516470                        tuberculose_protocolo_3.txt         17520   \n",
      "48466   coqueluche_nota_tecnica_1txt_notatecnica2023tx...           285   \n",
      "216636                         hepatite_c_protocolo_1.txt          2705   \n",
      "617515  zoonoses_manual_1txt_manual2023txt_manual2023t...           360   \n",
      "...                                                   ...           ...   \n",
      "615593  zoonoses_manual_1txt_manual2023txt_manual2023.txt          2779   \n",
      "459494                 sifilis_manual_1txt_manual2023.txt           697   \n",
      "555755  tuberculose_protocolo_6txt_protocolo2023txt_pr...         10111   \n",
      "235798  hepatite_e_protocolo_1txt_protocolo2023txt_pro...          2145   \n",
      "388526  peste_manual_1txt_manual2023txt_manual2023txt_...          1788   \n",
      "\n",
      "                                                    Texto  \n",
      "346681  dos sintomas respirat√≥rios, sem a necessidade ...  \n",
      "516470  O uso correto e o monitoramento dos equipament...  \n",
      "48466   ‚Ä¢ Crian√ßas menores de um ano, com menos de tr√™...  \n",
      "216636  Associadas. 3. ed. S√£o Paulo: Editora Atheneu,...  \n",
      "617515  deste Manual. Quando estas n√£o forem suficient...  \n",
      "...                                                   ...  \n",
      "615593  dos alimentos. A destina√ß√£o adequada de suas s...  \n",
      "459494  compreens√£o, pelo profissional cl√≠nico, de que...  \n",
      "555755  estrat√©gias de seguran√ßa alimentar, inser√ß√£o n...  \n",
      "235798  Modelo de laudo para Fluxograma 2 (Abordagem r...  \n",
      "388526  mundo afetando animais dom√©sticos e chegando a...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81d4a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando perguntas - Amostra:   0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:289: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "Gerando perguntas - Amostra: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:48<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Perguntas da amostra geradas com sucesso!\n",
      "üìÑ Arquivo salvo em: C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\\perguntas_amostra.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#gerador_perguntas_t5\n",
    "# === CONTINUAR AQUI COM O MESMO SCRIPT ===\n",
    "linhas = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Gerando perguntas - Amostra\"):\n",
    "    texto = str(row.get(\"Texto\", \"\")).strip()\n",
    "    if not texto:\n",
    "        continue\n",
    "    try:\n",
    "        perguntas = gerar_perguntas_t5(texto)\n",
    "        for pergunta in perguntas:\n",
    "            linhas.append({\n",
    "                \"Arquivo (Tema)\": row.get(\"Arquivo\", \"\"),\n",
    "                \"Pergunta sugerida\": pergunta,\n",
    "                \"Texto de origem\": texto\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro na linha {idx}: {e}\")\n",
    "\n",
    "# === SALVAR RESULTADO FINAL ===\n",
    "ARQUIVO_TESTE = os.path.join(PASTA_CORPUS, \"perguntas_amostra.xlsx\")\n",
    "df_resultado = pd.DataFrame(linhas)\n",
    "df_resultado.to_excel(ARQUIVO_TESTE, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas da amostra geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_TESTE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da234c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\isisi\\anaconda3\\lib\\site-packages (4.54.1)\n",
      "Requirement already satisfied: torch in c:\\users\\isisi\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\isisi\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\isisi\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\isisi\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\isisi\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isisi\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando perguntas:   0%|          | 0/624922 [00:00<?, ?it/s]c:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:289: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "Gerando perguntas:   1%|          | 3201/624922 [1:21:07<153:02:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Erro na linha 3200: [Errno 13] Permission denied: 'C:\\\\Users\\\\isisi\\\\Documents\\\\IAVS_PROJETO\\\\corpus_final\\\\perguntas_avancadas_20250802.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando perguntas:   4%|‚ñç         | 24604/624922 [9:43:12<237:09:42,  1.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     perguntas \u001b[38;5;241m=\u001b[39m gerar_perguntas_t5(texto)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pergunta \u001b[38;5;129;01min\u001b[39;00m perguntas:\n\u001b[0;32m     51\u001b[0m         linhas\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     52\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArquivo (Tema)\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArquivo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPergunta sugerida\u001b[39m\u001b[38;5;124m\"\u001b[39m: pergunta,\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto de origem\u001b[39m\u001b[38;5;124m\"\u001b[39m: texto\n\u001b[0;32m     55\u001b[0m         })\n",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m, in \u001b[0;36mgerar_perguntas_t5\u001b[1;34m(texto)\u001b[0m\n\u001b[0;32m     27\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(entrada, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# otimiza uso de mem√≥ria\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     saida_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     30\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m     31\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     32\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     33\u001b[0m         num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     34\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     )\n\u001b[0;32m     36\u001b[0m perguntas \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(g, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saida_ids]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(perguntas))\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:2652\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2646\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2647\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2648\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2649\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2650\u001b[0m     )\n\u001b[0;32m   2651\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2652\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2653\u001b[0m         input_ids,\n\u001b[0;32m   2654\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2655\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2656\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2657\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2658\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2659\u001b[0m     )\n\u001b[0;32m   2661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2662\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2665\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:4097\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   4094\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   4095\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m-> 4097\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   4100\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   4101\u001b[0m     model_outputs,\n\u001b[0;32m   4102\u001b[0m     model_kwargs,\n\u001b[0;32m   4103\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   4104\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1762\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1759\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[1;32m-> 1762\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[0;32m   1763\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1764\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1765\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1766\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1767\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m   1768\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1769\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1770\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1771\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1772\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1773\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1774\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1775\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1776\u001b[0m )\n\u001b[0;32m   1778\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1092\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m   1090\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m-> 1092\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m   1093\u001b[0m     hidden_states,\n\u001b[0;32m   1094\u001b[0m     causal_mask,\n\u001b[0;32m   1095\u001b[0m     position_bias,\n\u001b[0;32m   1096\u001b[0m     encoder_hidden_states,\n\u001b[0;32m   1097\u001b[0m     encoder_extended_attention_mask,\n\u001b[0;32m   1098\u001b[0m     encoder_decoder_position_bias,  \u001b[38;5;66;03m# as a positional argument for gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[0;32m   1100\u001b[0m     cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_layer_head_mask,\n\u001b[0;32m   1101\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1102\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1103\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1104\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1105\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1106\u001b[0m )\n\u001b[0;32m   1108\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:731\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    728\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[1;32m--> 731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](hidden_states)\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:342\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    341\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 342\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDenseReluDense(forwarded_states)\n\u001b[0;32m    343\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:287\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m--> 287\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwi(hidden_states)\n\u001b[0;32m    288\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[0;32m    289\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\isisi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o dos pacotes necess√°rios (pode deixar s√≥ na primeira c√©lula do notebook)\n",
    "%pip install transformers torch pandas openpyxl tqdm sentencepiece\n",
    "\n",
    "# === IMPORTA√á√ïES ===\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === CONFIGURA√á√ÉO DE CAMINHOS ===\n",
    "PASTA_CORPUS = r\"C:\\Users\\isisi\\Documents\\IAVS_PROJETO\\corpus_final\"\n",
    "ARQUIVO_PARAGRAFOS = os.path.join(PASTA_CORPUS, \"paragrafos_validos_corpus.xlsx\")\n",
    "ARQUIVO_SAIDA = os.path.join(PASTA_CORPUS, f\"perguntas_avancadas_{datetime.today().strftime('%Y%m%d')}.xlsx\")\n",
    "\n",
    "# === CARREGAR MODELO E TOKENIZER ===\n",
    "MODELO = \"valhalla/t5-base-qg-hl\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODELO)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODELO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# === FUN√á√ÉO DE GERA√á√ÉO DE PERGUNTAS ===\n",
    "def gerar_perguntas_t5(texto):\n",
    "    entrada = f\"generate question: {texto} </s>\"\n",
    "    input_ids = tokenizer.encode(entrada, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():  # otimiza uso de mem√≥ria\n",
    "        saida_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=64,\n",
    "            num_beams=4,\n",
    "            num_return_sequences=3,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    perguntas = [tokenizer.decode(g, skip_special_tokens=True) for g in saida_ids]\n",
    "    return list(set(perguntas))  # remove duplicadas\n",
    "\n",
    "# === CARREGAR PAR√ÅGRAFOS ===\n",
    "df = pd.read_excel(ARQUIVO_PARAGRAFOS)\n",
    "linhas = []\n",
    "\n",
    "# === PERCORRER PAR√ÅGRAFOS COM BARRA DE PROGRESSO ===\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Gerando perguntas\"):\n",
    "    texto = str(row.get(\"Texto\", \"\")).strip()\n",
    "    if not texto:\n",
    "        continue\n",
    "    try:\n",
    "        perguntas = gerar_perguntas_t5(texto)\n",
    "        for pergunta in perguntas:\n",
    "            linhas.append({\n",
    "                \"Arquivo (Tema)\": row.get(\"Arquivo\", \"\"),\n",
    "                \"Pergunta sugerida\": pergunta,\n",
    "                \"Texto de origem\": texto\n",
    "            })\n",
    "        # Checkpoint: salva a cada 100 par√°grafos\n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            pd.DataFrame(linhas).to_excel(ARQUIVO_SAIDA, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro na linha {idx}: {e}\")\n",
    "\n",
    "# === SALVAR RESULTADO FINAL ===\n",
    "df_resultado = pd.DataFrame(linhas)\n",
    "df_resultado.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "\n",
    "print(\"‚úÖ Perguntas geradas com sucesso!\")\n",
    "print(f\"üìÑ Arquivo salvo em: {ARQUIVO_SAIDA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
